# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M7DNg9hO5wNIw8sUU4OYRhrZtcvWDIUZ
"""

import streamlit as st
import torch
import torch.nn as nn
from transformers import BertTokenizer, BertModel
import pickle

# Load label encoder and tokenizer
with open("emotion_encoder.pkl", "rb") as f:
    emotion_encoder = pickle.load(f)

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# Sentiment mapping
positive = ['admiration', 'amusement', 'approval', 'caring', 'desire', 'excitement', 'gratitude', 'joy', 'love', 'optimism', 'pride', 'relief']
neutral = ['neutral', 'curiosity', 'realization', 'confusion']
negative = ['anger', 'annoyance', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'fear', 'grief', 'nervousness', 'remorse', 'sadness']

def get_sentiment(label):
    if label in positive:
        return 'positive'
    elif label in neutral:
        return 'neutral'
    else:
        return 'negative'

# Model class (must match training)
class EmotionToSentimentModel(nn.Module):
    def __init__(self, num_emotions):
        super().__init__()
        self.bert = BertModel.from_pretrained("bert-base-uncased")
        self.dropout = nn.Dropout(0.3)
        self.emotion_classifier = nn.Linear(768, num_emotions)

    def forward(self, input_ids, attention_mask):
        pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output
        dropped = self.dropout(pooled_output)
        return self.emotion_classifier(dropped)

# Load model
num_emotions = len(emotion_encoder.classes_)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = EmotionToSentimentModel(num_emotions)
model.load_state_dict(torch.load("best_model.pt", map_location=device))
model.to(device)
model.eval()

# Prediction function
def predict(text):
    with torch.no_grad():
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)
        logits = model(inputs['input_ids'], inputs['attention_mask'])
        probs = torch.softmax(logits, dim=1).squeeze().cpu().numpy()
        top_indices = probs.argsort()[-3:][::-1]
        top_emotions = [(emotion_encoder.inverse_transform([i])[0], round(probs[i]*100, 2)) for i in top_indices]
        final_emotion = top_emotions[0][0]
        final_sentiment = get_sentiment(final_emotion)
        return final_emotion, final_sentiment, top_emotions

# UI
st.title("ðŸŽ¬ Emotion & Sentiment Analyzer for Movie Reviews")
text = st.text_area("Enter a movie review:")

if st.button("Analyze"):
    if text.strip():
        emotion, sentiment, top3 = predict(text)
        st.success(f"**Emotion:** {emotion}")
        st.info(f"**Sentiment:** {sentiment}")
        st.markdown("### Top 3 Emotion Predictions:")
        for emo, conf in top3:
            st.markdown(f"- **{emo}**: {conf}%")
    else:
        st.warning("Please enter some text.")